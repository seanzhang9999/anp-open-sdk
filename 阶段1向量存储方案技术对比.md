# é˜¶æ®µ1å‘é‡å­˜å‚¨æ–¹æ¡ˆæŠ€æœ¯å¯¹æ¯”ï¼šSQLite vs å‘é‡æ•°æ®åº“

## ğŸ¯ é—®é¢˜åˆ†æ

åœ¨**é˜¶æ®µ1: OpenAI API + Redisç¼“å­˜**ä¸­ï¼Œæ ¸å¿ƒé—®é¢˜æ˜¯é€‰æ‹©åˆé€‚çš„å‘é‡å­˜å‚¨æ–¹æ¡ˆï¼š
- æ˜¯å¦éœ€è¦ä¸“ä¸šå‘é‡æ•°æ®åº“ï¼Ÿ
- SQLite + å‘é‡æ‰©å±•æ˜¯å¦è¶³å¤Ÿï¼Ÿ
- å†…å­˜å‘é‡ç¼“å­˜çš„å¯è¡Œæ€§ï¼Ÿ

## ğŸ“Š æŠ€æœ¯æ–¹æ¡ˆå¯¹æ¯”

### æ–¹æ¡ˆAï¼šSQLite + sqlite-vssï¼ˆæ¨èï¼‰

#### æŠ€æœ¯å®ç°
```python
import sqlite3
import sqlite_vss
import numpy as np
from typing import List, Tuple

class SQLiteVectorMemory:
    def __init__(self, db_path: str):
        self.db_path = db_path
        self.conn = sqlite3.connect(db_path, check_same_thread=False)
        self._setup_vector_tables()
        
    def _setup_vector_tables(self):
        """åˆå§‹åŒ–SQLiteå‘é‡æœç´¢"""
        # åŠ è½½sqlite-vssæ‰©å±•
        self.conn.enable_load_extension(True)
        sqlite_vss.load(self.conn)
        
        # åˆ›å»ºå‘é‡è¡¨
        self.conn.execute("""
            CREATE VIRTUAL TABLE IF NOT EXISTS memory_vectors USING vss0(
                embedding(1536),  -- OpenAI ada-002ç»´åº¦
                +memory_id INTEGER,
                +content TEXT,
                +memory_type TEXT,
                +created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        # åˆ›å»ºå¸¸è§„å†…å®¹è¡¨ï¼ˆå…³è”å­˜å‚¨ï¼‰
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS memories (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                content TEXT NOT NULL,
                memory_type TEXT DEFAULT 'general',
                metadata JSON,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        self.conn.commit()
    
    async def add_memory(self, content: str, embedding: List[float], 
                        memory_type: str = "general", metadata: dict = None) -> int:
        """æ·»åŠ è®°å¿†å’Œå‘é‡"""
        # 1. æ’å…¥å¸¸è§„å†…å®¹
        cursor = self.conn.execute("""
            INSERT INTO memories (content, memory_type, metadata)
            VALUES (?, ?, ?)
        """, (content, memory_type, json.dumps(metadata or {})))
        
        memory_id = cursor.lastrowid
        
        # 2. æ’å…¥å‘é‡ç´¢å¼•
        self.conn.execute("""
            INSERT INTO memory_vectors (rowid, embedding, memory_id, content, memory_type)
            VALUES (?, ?, ?, ?, ?)
        """, (memory_id, embedding, memory_id, content, memory_type))
        
        self.conn.commit()
        return memory_id
    
    def search_similar_memories(self, query_embedding: List[float], 
                              limit: int = 5, threshold: float = 0.8) -> List[Tuple]:
        """å‘é‡ç›¸ä¼¼åº¦æœç´¢"""
        cursor = self.conn.execute("""
            SELECT m.id, m.content, m.memory_type, m.metadata, 
                   v.distance
            FROM memory_vectors v
            JOIN memories m ON v.memory_id = m.id
            WHERE v.embedding MATCH ? AND v.distance < ?
            ORDER BY v.distance
            LIMIT ?
        """, (query_embedding, 1.0 - threshold, limit))
        
        return cursor.fetchall()
```

**ä¼˜åŠ¿ï¼š**
- âœ… **è½»é‡çº§**ï¼šæ— éœ€é¢å¤–æœåŠ¡ï¼ŒåŸºäºSQLite
- âœ… **æŒä¹…åŒ–**ï¼šæ•°æ®æ°¸ä¹…å­˜å‚¨ï¼Œé‡å¯ä¸ä¸¢å¤±
- âœ… **ACIDæ”¯æŒ**ï¼šäº‹åŠ¡ä¸€è‡´æ€§ä¿éšœ
- âœ… **é›†æˆç®€å•**ï¼šä¸ç°æœ‰SQLiteæ¶æ„æ— ç¼ç»“åˆ
- âœ… **å‘é‡æœç´¢**ï¼šæ”¯æŒé«˜æ•ˆç›¸ä¼¼åº¦æœç´¢

**åŠ£åŠ¿ï¼š**
- âŒ **æ€§èƒ½é™åˆ¶**ï¼šå¤§è§„æ¨¡å‘é‡æœç´¢æ€§èƒ½ä¸å¦‚ä¸“ä¸šå‘é‡DB
- âŒ **æ‰©å±•æ€§**ï¼šå•æœºå­˜å‚¨ï¼Œæ— æ³•åˆ†å¸ƒå¼æ‰©å±•

### æ–¹æ¡ˆBï¼šå†…å­˜å‘é‡ç¼“å­˜ + SQLiteæŒä¹…åŒ–

#### æŠ€æœ¯å®ç°
```python
import faiss
import numpy as np
import pickle
from typing import List, Dict, Tuple

class MemoryVectorCache:
    def __init__(self, db_path: str, dimension: int = 1536):
        self.db_path = db_path
        self.dimension = dimension
        
        # FAISSå†…å­˜ç´¢å¼•
        self.index = faiss.IndexFlatIP(dimension)  # å†…ç§¯ç›¸ä¼¼åº¦
        self.memory_map = {}  # ID -> å†…å®¹æ˜ å°„
        self.next_id = 0
        
        # SQLiteæŒä¹…åŒ–è¿æ¥
        self.conn = sqlite3.connect(db_path)
        self._setup_persistence_tables()
        self._load_from_disk()
    
    def _setup_persistence_tables(self):
        """è®¾ç½®æŒä¹…åŒ–è¡¨ç»“æ„"""
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS vector_cache (
                memory_id INTEGER PRIMARY KEY,
                content TEXT NOT NULL,
                embedding BLOB NOT NULL,
                memory_type TEXT DEFAULT 'general',
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        self.conn.commit()
    
    def _load_from_disk(self):
        """ä»SQLiteåŠ è½½å‘é‡åˆ°å†…å­˜"""
        cursor = self.conn.execute("""
            SELECT memory_id, content, embedding, memory_type 
            FROM vector_cache ORDER BY memory_id
        """)
        
        embeddings = []
        for row in cursor.fetchall():
            memory_id, content, embedding_blob, memory_type = row
            embedding = pickle.loads(embedding_blob)
            
            # åŠ è½½åˆ°FAISSç´¢å¼•
            embeddings.append(embedding)
            self.memory_map[memory_id] = {
                'content': content,
                'memory_type': memory_type
            }
            self.next_id = max(self.next_id, memory_id + 1)
        
        if embeddings:
            embeddings_array = np.array(embeddings, dtype=np.float32)
            self.index.add(embeddings_array)
    
    async def add_memory(self, content: str, embedding: List[float], 
                        memory_type: str = "general") -> int:
        """æ·»åŠ è®°å¿†åˆ°å†…å­˜ç¼“å­˜å’ŒæŒä¹…åŒ–"""
        memory_id = self.next_id
        self.next_id += 1
        
        # 1. æ·»åŠ åˆ°å†…å­˜ç´¢å¼•
        embedding_array = np.array([embedding], dtype=np.float32)
        self.index.add(embedding_array)
        
        # 2. æ›´æ–°å†…å­˜æ˜ å°„
        self.memory_map[memory_id] = {
            'content': content,
            'memory_type': memory_type
        }
        
        # 3. æŒä¹…åŒ–åˆ°SQLite
        embedding_blob = pickle.dumps(embedding)
        self.conn.execute("""
            INSERT INTO vector_cache (memory_id, content, embedding, memory_type)
            VALUES (?, ?, ?, ?)
        """, (memory_id, content, embedding_blob, memory_type))
        self.conn.commit()
        
        return memory_id
    
    def search_similar_memories(self, query_embedding: List[float], 
                              k: int = 5) -> List[Tuple]:
        """å†…å­˜å‘é‡æœç´¢"""
        if self.index.ntotal == 0:
            return []
        
        query_array = np.array([query_embedding], dtype=np.float32)
        
        # FAISSæœç´¢
        similarities, indices = self.index.search(query_array, k)
        
        results = []
        for i, (similarity, idx) in enumerate(zip(similarities[0], indices[0])):
            if idx < len(self.memory_map):
                memory_info = self.memory_map[idx]
                results.append((
                    memory_info['content'],
                    float(similarity),
                    memory_info['memory_type']
                ))
        
        return results
```

**ä¼˜åŠ¿ï¼š**
- âœ… **æé«˜æ€§èƒ½**ï¼šå†…å­˜æ“ä½œï¼Œæ¯«ç§’çº§æœç´¢
- âœ… **FAISSä¼˜åŒ–**ï¼šä¸“ä¸šå‘é‡æœç´¢åº“
- âœ… **çµæ´»æ€§**ï¼šå¯ä»¥åˆ‡æ¢ä¸åŒç´¢å¼•ç±»å‹
- âœ… **æŒä¹…åŒ–**ï¼šå®šæœŸä¿å­˜åˆ°SQLite

**åŠ£åŠ¿ï¼š**
- âŒ **å†…å­˜å ç”¨**ï¼šæ‰€æœ‰å‘é‡å¸¸é©»å†…å­˜
- âŒ **å¯åŠ¨æ—¶é—´**ï¼šéœ€è¦åŠ è½½æ‰€æœ‰å‘é‡åˆ°å†…å­˜
- âŒ **æ•°æ®ä¸€è‡´æ€§**ï¼šå†…å­˜å’Œç£ç›˜å¯èƒ½ä¸åŒæ­¥

### æ–¹æ¡ˆCï¼šä¸“ä¸šå‘é‡æ•°æ®åº“ï¼ˆä¸æ¨èé˜¶æ®µ1ï¼‰

```python
# ChromaDBç¤ºä¾‹
import chromadb

class ChromaDBVectorMemory:
    def __init__(self, collection_name: str = "anp_memories"):
        self.client = chromadb.Client()
        self.collection = self.client.create_collection(
            name=collection_name,
            metadata={"hnsw:space": "cosine"}
        )
    
    async def add_memory(self, content: str, embedding: List[float], 
                        memory_id: str) -> None:
        self.collection.add(
            embeddings=[embedding],
            documents=[content],
            ids=[memory_id]
        )
    
    def search_similar_memories(self, query_embedding: List[float], 
                              n_results: int = 5) -> List:
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=n_results
        )
        return results
```

**ä¼˜åŠ¿ï¼š**
- âœ… **ä¸“ä¸šæ€§èƒ½**ï¼šä¸ºå‘é‡æœç´¢ä¼˜åŒ–
- âœ… **ä¸°å¯ŒåŠŸèƒ½**ï¼šæ”¯æŒè¿‡æ»¤ã€èšåˆç­‰é«˜çº§åŠŸèƒ½
- âœ… **å¯æ‰©å±•æ€§**ï¼šæ”¯æŒåˆ†å¸ƒå¼éƒ¨ç½²

**åŠ£åŠ¿ï¼š**
- âŒ **å¤æ‚åº¦é«˜**ï¼šéœ€è¦é¢å¤–æœåŠ¡å’Œä¾èµ–
- âŒ **èµ„æºå ç”¨**ï¼šç‹¬ç«‹è¿›ç¨‹ï¼Œå ç”¨æ›´å¤šèµ„æº
- âŒ **è¿‡åº¦è®¾è®¡**ï¼šé˜¶æ®µ1ä¸éœ€è¦å¦‚æ­¤å¤æ‚

## ğŸ¯ é˜¶æ®µ1æ¨èæ–¹æ¡ˆ

### æœ€ä¼˜é€‰æ‹©ï¼šSQLite + sqlite-vss + å†…å­˜LRUç¼“å­˜

```python
from functools import lru_cache
import sqlite_vss

class OptimalVectorMemory:
    def __init__(self, db_path: str, cache_size: int = 1000):
        self.db_path = db_path
        self.cache_size = cache_size
        self.conn = sqlite3.connect(db_path)
        sqlite_vss.load(self.conn)
        self._setup_tables()
    
    @lru_cache(maxsize=1000)
    def _cached_search(self, query_hash: str, query_embedding_str: str) -> List:
        """LRUç¼“å­˜çš„æœç´¢ç»“æœ"""
        query_embedding = eval(query_embedding_str)  # å®é™…åº”ç”¨ä¸­ç”¨æ›´å®‰å…¨çš„æ–¹æ³•
        return self._raw_search(query_embedding)
    
    def _raw_search(self, query_embedding: List[float]) -> List:
        """åŸå§‹å‘é‡æœç´¢"""
        cursor = self.conn.execute("""
            SELECT content, distance FROM memory_vectors 
            WHERE embedding MATCH ? 
            ORDER BY distance LIMIT 5
        """, (query_embedding,))
        return cursor.fetchall()
    
    def search_with_cache(self, query_embedding: List[float]) -> List:
        """å¸¦ç¼“å­˜çš„æœç´¢"""
        import hashlib
        query_hash = hashlib.md5(str(query_embedding).encode()).hexdigest()
        return self._cached_search(query_hash, str(query_embedding))
```

## âœ… æœ€ç»ˆå»ºè®®

**é˜¶æ®µ1æ¨èï¼šSQLite + sqlite-vss + å†…å­˜ç¼“å­˜**

### ç†ç”±ï¼š
1. **ç®€å•æ€§**ï¼šæ— éœ€é¢å¤–æœåŠ¡ï¼ŒåŸºäºç°æœ‰SQLiteæ¶æ„
2. **å¯é æ€§**ï¼šSQLiteçš„ACIDç‰¹æ€§ä¿è¯æ•°æ®ä¸€è‡´æ€§
3. **æ€§èƒ½å¹³è¡¡**ï¼šsqlite-vssæä¾›è¶³å¤Ÿçš„å‘é‡æœç´¢æ€§èƒ½
4. **æ¸è¿›å¼**ï¼šåç»­å¯ä»¥æ— ç¼å‡çº§åˆ°æ›´å¤æ‚æ–¹æ¡ˆ

### å®æ–½ç­–ç•¥ï¼š
```python
# é˜¶æ®µ1æ ¸å¿ƒæ¶æ„
class Stage1VectorMemory:
    def __init__(self):
        self.sqlite_vector = SQLiteVectorMemory("memory.db")
        self.redis_cache = EmbeddingCache(redis_client)  # embeddingç¼“å­˜
        self.result_cache = {}  # æœç´¢ç»“æœLRUç¼“å­˜
        
    async def add_memory(self, content: str):
        # 1. ç”Ÿæˆembeddingï¼ˆå¸¦Redisç¼“å­˜ï¼‰
        embedding = await self.get_cached_embedding(content)
        # 2. å­˜å‚¨åˆ°SQLiteå‘é‡è¡¨
        return await self.sqlite_vector.add_memory(content, embedding)
    
    async def search_memories(self, query: str):
        # 1. ç”Ÿæˆquery embedding
        query_embedding = await self.get_cached_embedding(query)
        # 2. SQLiteå‘é‡æœç´¢ï¼ˆå¸¦ç»“æœç¼“å­˜ï¼‰
        return self.sqlite_vector.search_similar_memories(query_embedding)
```

è¿™ä¸ªæ–¹æ¡ˆæ—¢ä¿æŒäº†æ¶æ„ç®€å•æ€§ï¼Œåˆå…·å¤‡äº†å‘æ›´å¤æ‚æ–¹æ¡ˆæ¼”è¿›çš„èƒ½åŠ›ï¼