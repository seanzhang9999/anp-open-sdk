# Memoryç³»ç»Ÿå‘é‡æœç´¢Embeddingæ–¹æ¡ˆæŠ€æœ¯åˆ†æ

## ğŸ¯ æ–¹æ¡ˆæ¦‚è¿°

åŸºäºæ‚¨é€‰æ‹©çš„LLM API embeddingæœåŠ¡æ–¹æ¡ˆï¼Œæˆ‘å°†è¯¦ç»†åˆ†æå„ç§embeddingæŠ€æœ¯æ–¹æ¡ˆçš„å®ç°ç»†èŠ‚ã€æ€§èƒ½ç‰¹å¾å’Œé€‚ç”¨åœºæ™¯ã€‚

## ğŸ“Š æŠ€æœ¯æ–¹æ¡ˆå¯¹æ¯”åˆ†æ

### 1. LLM API EmbeddingæœåŠ¡ï¼ˆæ¨èæ–¹æ¡ˆï¼‰

#### ğŸ”¥ OpenAI text-embedding-ada-002
```python
import openai
from typing import List, Dict
import numpy as np
import asyncio

class OpenAIEmbeddingProvider:
    def __init__(self, api_key: str):
        self.client = openai.OpenAI(api_key=api_key)
        self.model = "text-embedding-ada-002"
        self.dimension = 1536  # ada-002çš„å‘é‡ç»´åº¦
        self.max_tokens_per_request = 8191
        
    async def get_embeddings(self, texts: List[str]) -> List[List[float]]:
        """æ‰¹é‡è·å–æ–‡æœ¬embedding"""
        response = await self.client.embeddings.create(
            model=self.model,
            input=texts,
            encoding_format="float"
        )
        return [data.embedding for data in response.data]
    
    async def get_single_embedding(self, text: str) -> List[float]:
        """è·å–å•ä¸ªæ–‡æœ¬embedding"""
        embeddings = await self.get_embeddings([text])
        return embeddings[0]
```

**æŠ€æœ¯ç‰¹å¾ï¼š**
- âœ… **è´¨é‡æé«˜**ï¼š1536ç»´å‘é‡ï¼Œè¯­ä¹‰ç†è§£èƒ½åŠ›å¼º
- âœ… **æ— æœ¬åœ°èµ„æºå ç”¨**ï¼šä¸éœ€è¦ä¸‹è½½æ¨¡å‹æ–‡ä»¶
- âœ… **æ”¯æŒæ‰¹é‡å¤„ç†**ï¼šæœ€å¤š2048ä¸ªtoken/è¯·æ±‚
- âŒ **APIè°ƒç”¨æˆæœ¬**ï¼š$0.0001/1K tokens
- âŒ **ç½‘ç»œä¾èµ–**ï¼šéœ€è¦ç¨³å®šç½‘ç»œè¿æ¥
- âŒ **éšç§è€ƒè™‘**ï¼šæ–‡æœ¬æ•°æ®éœ€å‘é€åˆ°å¤–éƒ¨æœåŠ¡

#### ğŸš€ å…¶ä»–APIé€‰æ‹©
```python
# Azure OpenAI
class AzureEmbeddingProvider:
    def __init__(self, endpoint: str, api_key: str, deployment_name: str):
        self.client = openai.AzureOpenAI(
            azure_endpoint=endpoint,
            api_key=api_key,
            api_version="2023-12-01-preview"
        )
        self.deployment_name = deployment_name

# Google Vertex AI
class VertexAIEmbeddingProvider:
    def __init__(self, project_id: str):
        from google.cloud import aiplatform
        aiplatform.init(project=project_id)
        self.model = "textembedding-gecko@001"
        self.dimension = 768

# ç™¾åº¦æ–‡å¿ƒä¸€è¨€
class ErnieBotEmbeddingProvider:
    def __init__(self, api_key: str, secret_key: str):
        self.api_key = api_key
        self.secret_key = secret_key
        self.dimension = 384
```

### 2. æœ¬åœ°Embeddingæ¨¡å‹å¯¹æ¯”

#### ğŸ  Sentence-Transformersæ–¹æ¡ˆ
```python
from sentence_transformers import SentenceTransformer
import torch

class LocalEmbeddingProvider:
    def __init__(self, model_name: str = "all-MiniLM-L6-v2"):
        self.model = SentenceTransformer(model_name)
        self.dimension = self.model.get_sentence_embedding_dimension()
        
    def get_embeddings(self, texts: List[str]) -> List[List[float]]:
        """æ‰¹é‡è·å–embedding"""
        embeddings = self.model.encode(texts, convert_to_tensor=False)
        return embeddings.tolist()
    
    def get_single_embedding(self, text: str) -> List[float]:
        embedding = self.model.encode([text], convert_to_tensor=False)
        return embedding[0].tolist()
```

**æ¨¡å‹å¯¹æ¯”ï¼š**
| æ¨¡å‹ | ç»´åº¦ | å¤§å° | æ€§èƒ½ | é€‚ç”¨åœºæ™¯ |
|------|------|------|------|----------|
| all-MiniLM-L6-v2 | 384 | 80MB | å¿«é€Ÿ | é€šç”¨æ–‡æœ¬ |
| paraphrase-multilingual-MiniLM-L12-v2 | 384 | 418MB | ä¸­ç­‰ | å¤šè¯­è¨€ |
| all-mpnet-base-v2 | 768 | 420MB | é«˜è´¨é‡ | è‹±æ–‡ä¸“ç”¨ |
| text2vec-base-chinese | 768 | 400MB | é«˜è´¨é‡ | ä¸­æ–‡ä¸“ç”¨ |

### 3. æ··åˆEmbeddingç­–ç•¥è®¾è®¡

```python
class HybridEmbeddingProvider:
    def __init__(self, 
                 api_provider: OpenAIEmbeddingProvider,
                 local_provider: LocalEmbeddingProvider,
                 strategy: str = "smart"):
        self.api_provider = api_provider
        self.local_provider = local_provider
        self.strategy = strategy
        self.api_usage_count = 0
        self.monthly_limit = 10000  # APIè°ƒç”¨é™åˆ¶
        
    async def get_embedding(self, text: str, force_api: bool = False) -> List[float]:
        """æ™ºèƒ½é€‰æ‹©embeddingæ–¹æ¡ˆ"""
        if self.strategy == "smart":
            # å…³é”®å†…å®¹ä½¿ç”¨APIï¼Œæ™®é€šå†…å®¹ä½¿ç”¨æœ¬åœ°
            if self._is_critical_content(text) or force_api:
                if self.api_usage_count < self.monthly_limit:
                    self.api_usage_count += 1
                    return await self.api_provider.get_single_embedding(text)
            
            # é»˜è®¤ä½¿ç”¨æœ¬åœ°æ¨¡å‹
            return self.local_provider.get_single_embedding(text)
        
        elif self.strategy == "fallback":
            # ä¼˜å…ˆAPIï¼Œå¤±è´¥æ—¶é™çº§åˆ°æœ¬åœ°
            try:
                return await self.api_provider.get_single_embedding(text)
            except Exception:
                return self.local_provider.get_single_embedding(text)
    
    def _is_critical_content(self, text: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºå…³é”®å†…å®¹"""
        critical_keywords = ["é‡è¦", "ç´§æ€¥", "å…³é”®", "æ ¸å¿ƒ"]
        return any(keyword in text for keyword in critical_keywords)
```

## ğŸ—ï¸ Memoryç³»ç»Ÿé›†æˆå®ç°

### SQLiteå‘é‡æ‰©å±•é›†æˆ
```python
import sqlite3
import sqlite_vss
from typing import List, Tuple

class MemoryVectorSearch:
    def __init__(self, db_path: str, embedding_provider):
        self.db_path = db_path
        self.embedding_provider = embedding_provider
        self.conn = sqlite3.connect(db_path)
        self._setup_vector_search()
    
    def _setup_vector_search(self):
        """åˆå§‹åŒ–å‘é‡æœç´¢åŠŸèƒ½"""
        # åŠ è½½sqlite-vssæ‰©å±•
        self.conn.enable_load_extension(True)
        sqlite_vss.load(self.conn)
        
        # åˆ›å»ºå‘é‡è¡¨
        self.conn.execute("""
            CREATE VIRTUAL TABLE IF NOT EXISTS memory_vectors USING vss0(
                id INTEGER PRIMARY KEY,
                content_embedding(1536),  -- OpenAI embeddingç»´åº¦
                content TEXT,
                memory_type TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
    async def add_memory(self, content: str, memory_type: str = "general") -> int:
        """æ·»åŠ è®°å¿†å¹¶ç”Ÿæˆå‘é‡"""
        # ç”Ÿæˆembedding
        embedding = await self.embedding_provider.get_single_embedding(content)
        
        # å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“
        cursor = self.conn.execute("""
            INSERT INTO memory_vectors (content_embedding, content, memory_type)
            VALUES (?, ?, ?)
        """, (embedding, content, memory_type))
        
        memory_id = cursor.lastrowid
        self.conn.commit()
        return memory_id
    
    async def search_similar_memories(self, 
                                    query: str, 
                                    limit: int = 5,
                                    memory_type: str = None) -> List[Tuple[str, float]]:
        """è¯­ä¹‰æœç´¢ç›¸ä¼¼è®°å¿†"""
        # ç”ŸæˆæŸ¥è¯¢embedding
        query_embedding = await self.embedding_provider.get_single_embedding(query)
        
        # å‘é‡ç›¸ä¼¼åº¦æœç´¢
        sql = """
            SELECT content, distance
            FROM memory_vectors
            WHERE content_embedding MATCH ?
        """
        params = [query_embedding]
        
        if memory_type:
            sql += " AND memory_type = ?"
            params.append(memory_type)
            
        sql += f" ORDER BY distance LIMIT {limit}"
        
        cursor = self.conn.execute(sql, params)
        return cursor.fetchall()
```

### ç¼“å­˜ä¼˜åŒ–ç­–ç•¥
```python
import json
import hashlib
from functools import lru_cache
import redis

class EmbeddingCache:
    def __init__(self, redis_client=None, use_memory_cache: bool = True):
        self.redis_client = redis_client
        self.use_memory_cache = use_memory_cache
        
    def _get_cache_key(self, text: str, model: str) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        content_hash = hashlib.md5(text.encode()).hexdigest()
        return f"embedding:{model}:{content_hash}"
    
    @lru_cache(maxsize=1000)
    def _memory_cache_get(self, cache_key: str) -> List[float]:
        """å†…å­˜ç¼“å­˜è·å–"""
        return None
    
    async def get_cached_embedding(self, 
                                 text: str, 
                                 model: str) -> List[float]:
        """è·å–ç¼“å­˜çš„embedding"""
        cache_key = self._get_cache_key(text, model)
        
        # å†…å­˜ç¼“å­˜
        if self.use_memory_cache:
            cached = self._memory_cache_get(cache_key)
            if cached:
                return cached
        
        # Redisç¼“å­˜
        if self.redis_client:
            cached_data = self.redis_client.get(cache_key)
            if cached_data:
                return json.loads(cached_data)
        
        return None
    
    async def cache_embedding(self, 
                            text: str, 
                            model: str, 
                            embedding: List[float],
                            ttl: int = 86400):
        """ç¼“å­˜embedding"""
        cache_key = self._get_cache_key(text, model)
        embedding_json = json.dumps(embedding)
        
        # Redisç¼“å­˜ï¼ˆæŒä¹…åŒ–ï¼‰
        if self.redis_client:
            self.redis_client.setex(cache_key, ttl, embedding_json)
        
        # å†…å­˜ç¼“å­˜é€šè¿‡LRUè‡ªåŠ¨ç®¡ç†
```

## ğŸ’° æˆæœ¬ä¸æ€§èƒ½åˆ†æ

### APIæˆæœ¬ä¼°ç®—
```python
class CostAnalyzer:
    def __init__(self):
        self.pricing = {
            "openai-ada-002": 0.0001,  # $0.0001/1K tokens
            "azure-openai": 0.0001,
            "vertex-ai": 0.000025,    # Googleæ›´ä¾¿å®œ
            "local-model": 0.0        # ä»…ç”µè´¹æˆæœ¬
        }
    
    def estimate_monthly_cost(self, 
                            daily_queries: int,
                            avg_tokens_per_query: int,
                            provider: str) -> float:
        """ä¼°ç®—æœˆåº¦æˆæœ¬"""
        monthly_tokens = daily_queries * 30 * avg_tokens_per_query
        cost_per_1k = self.pricing.get(provider, 0)
        return (monthly_tokens / 1000) * cost_per_1k
    
    def compare_costs(self, daily_queries: int = 1000):
        """æˆæœ¬å¯¹æ¯”åˆ†æ"""
        results = {}
        for provider, price in self.pricing.items():
            monthly_cost = self.estimate_monthly_cost(daily_queries, 100, provider)
            results[provider] = {
                "monthly_cost": monthly_cost,
                "cost_per_query": monthly_cost / (daily_queries * 30)
            }
        return results
```

### æ€§èƒ½åŸºå‡†æµ‹è¯•
```python
import time
import asyncio

class PerformanceBenchmark:
    async def benchmark_provider(self, 
                               provider, 
                               test_texts: List[str]) -> Dict:
        """åŸºå‡†æµ‹è¯•embeddingæä¾›è€…"""
        start_time = time.time()
        
        # æ‰¹é‡å¤„ç†æµ‹è¯•
        if hasattr(provider, 'get_embeddings'):
            embeddings = await provider.get_embeddings(test_texts)
        else:
            embeddings = [await provider.get_single_embedding(text) 
                         for text in test_texts]
        
        end_time = time.time()
        
        return {
            "total_time": end_time - start_time,
            "texts_processed": len(test_texts),
            "avg_time_per_text": (end_time - start_time) / len(test_texts),
            "embeddings_dimension": len(embeddings[0]) if embeddings else 0
        }
```

## ğŸ¯ æ¨èå®æ–½æ–¹æ¡ˆ

åŸºäºæ‚¨é€‰æ‹©çš„LLM APIæ–¹æ¡ˆï¼Œæ¨èä»¥ä¸‹å®æ–½ç­–ç•¥ï¼š

### é˜¶æ®µ1ï¼šåŸºç¡€APIé›†æˆ
1. **ä¼˜å…ˆOpenAI text-embedding-ada-002**ï¼šè´¨é‡æœ€é«˜ï¼Œç”Ÿæ€æœ€æˆç†Ÿ
2. **å®ç°åŸºç¡€ç¼“å­˜**ï¼šRedis + å†…å­˜åŒå±‚ç¼“å­˜å‡å°‘APIè°ƒç”¨
3. **SQLite-vssé›†æˆ**ï¼šå‘é‡æœç´¢èƒ½åŠ›é›†æˆåˆ°Memoryç³»ç»Ÿ

### é˜¶æ®µ2ï¼šä¼˜åŒ–ä¸é™çº§
1. **æœ¬åœ°æ¨¡å‹å¤‡é€‰**ï¼šsentence-transformersä½œä¸ºç¦»çº¿å¤‡é€‰
2. **æ™ºèƒ½è°ƒåº¦**ï¼šå…³é”®å†…å®¹ç”¨APIï¼Œæ™®é€šå†…å®¹ç”¨æœ¬åœ°
3. **æˆæœ¬æ§åˆ¶**ï¼šæœˆåº¦é™é¢å’Œä½¿ç”¨ç›‘æ§

### é˜¶æ®µ3ï¼šé«˜çº§åŠŸèƒ½
1. **å¤šæ¨¡å‹èåˆ**ï¼šä¸åŒåœºæ™¯ä½¿ç”¨ä¸åŒembeddingæ¨¡å‹
2. **åœ¨çº¿å­¦ä¹ **ï¼šåŸºäºç”¨æˆ·åé¦ˆä¼˜åŒ–embeddingé€‰æ‹©
3. **è¾¹ç¼˜è®¡ç®—**ï¼šéƒ¨åˆ†embeddingè®¡ç®—ä¸‹æ²‰åˆ°è¾¹ç¼˜èŠ‚ç‚¹

è¿™æ ·çš„æ–¹æ¡ˆæ—¢ä¿è¯äº†embeddingè´¨é‡ï¼Œåˆæ§åˆ¶äº†æˆæœ¬ï¼ŒåŒæ—¶å…·å¤‡è‰¯å¥½çš„æ‰©å±•æ€§ï¼